{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake Detection: VGG Model\n",
    "\n",
    "**Objective**: Use transfer learning for feature extraction with VGG16 followed by SVM classification model  \n",
    "\n",
    "**VGG16 Models**: \n",
    "1. Binary Classification\n",
    "2. Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "% matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "#Data Processing\n",
    "from skimage import io\n",
    "import os\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import sklearn\n",
    "\n",
    "#Neural Networks\n",
    "from tensorflow.python import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#Models\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Split\n",
    "\n",
    "Load the DeepFake dataset to randomly divide it into train and test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your dataset\n",
    "DATASET_PATH = '/mnt/disks/user/project/Dataset/'\n",
    "deepfake_class = ['original/clean_frames','FaceSwap/clean_frames', 'Reenactment/clean_frames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: load the deepfake dataset and divide them into train and test with each having samples of the different classes\n",
    "input:\n",
    "    i.dataset_path: string: the main dataset folder path \n",
    "    ii.train_ratio: float: the ratio of the dataset that will be used for training the model. Eg: 0.8\n",
    "    iii. fake_class: string array: the different deepfake classes\n",
    "output:\n",
    "    i. train_set, test_set: dictionary of image paths as key and deepfake class as value\n",
    "    ii. X_train, X_test: array of image paths \n",
    "    iii. y_train, y_test: array of corresponding deepfake classes \n",
    "'''\n",
    "def MultiDatasetSplit(DATASET_PATH, train_ratio,fake_cls):\n",
    "    test_set = {}\n",
    "    train_set = {}\n",
    "    list_IDs = []\n",
    "    labels = {}\n",
    "    for i, cls in enumerate(fake_cls):\n",
    "        paths = glob.glob(os.path.join(DATASET_PATH, cls,'*/*.jpg'))\n",
    "        #balancing the dataset\n",
    "        balance_paths = random.sample(paths,2000)\n",
    "\n",
    "        brk_point = int(len(balance_paths)*train_ratio)\n",
    "        for j in range(len(balance_paths)):\n",
    "            if j <= brk_point:\n",
    "                train_set.update({balance_paths[j]:i})\n",
    "            else:\n",
    "                test_set.update({balance_paths[j]:i})\n",
    "    \n",
    "    X_train = [X for X in train_set.keys()] \n",
    "    y_train = [y for y in train_set.values()]\n",
    "    X_test = [X for X in test_set.keys()]\n",
    "    y_test = [y for y in test_set.values()]\n",
    "    return train_set, test_set, X_train,y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: load the deepfake dataset and divide them into train and test with each having samples of the different classes\n",
    "input:\n",
    "    i.dataset_path: string: the main dataset folder path \n",
    "    ii.train_ratio: float: the ratio of the dataset that will be used for training the model. Eg: 0.8\n",
    "    iii. fake_class: string array: the different deepfake classes\n",
    "output:\n",
    "    i. train_set, test_set: dictionary of image paths as key and deepfake class as value\n",
    "    ii. X_train, X_test: array of image paths \n",
    "    iii. y_train, y_test: array of corresponding deepfake classes \n",
    "'''\n",
    "def BinaryDatasetSplit(DATASET_PATH, train_ratio,fake_cls):\n",
    "    test_set = {}\n",
    "    train_set = {}\n",
    "    list_IDs = []\n",
    "    labels = {}\n",
    "    for i, cls in enumerate(fake_cls):\n",
    "        paths = glob.glob(os.path.join(DATASET_PATH, cls,'*/*.jpg'))\n",
    "        if i == 0:\n",
    "            paths = random.sample(paths,4000)\n",
    "        else:\n",
    "            paths = random.sample(paths,2000)\n",
    "        brk_point = int(len(paths)*train_ratio)\n",
    "        for j in range(len(paths)):\n",
    "            if j <= brk_point:\n",
    "                if i == 0:\n",
    "                    train_set.update({paths[j]:0})\n",
    "                else: \n",
    "                    train_set.update({paths[j]:1})\n",
    "            else:\n",
    "                if i == 0:\n",
    "                    test_set.update({paths[j]:0})\n",
    "                else:\n",
    "                    test_set.update({paths[j]:1})\n",
    "\n",
    "    X_train = [X for X in train_set.keys()] \n",
    "    y_train = [y for y in train_set.values()]\n",
    "    X_test = [X for X in test_set.keys()]\n",
    "    y_test = [y for y in test_set.values()]\n",
    "    return train_set, test_set, X_train,y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train_set, b_test_set, b_train_X, b_train_y, b_test_X, b_test_y = BinaryDatasetSplit(DATASET_PATH,0.7,deepfake_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train_set, m_test_set, m_train_X, m_train_y, m_test_X, m_test_y = MultiDatasetSplit(DATASET_PATH,0.7,deepfake_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2801, 1: 2802})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(b_train_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1401, 1: 1401, 2: 1401})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(m_train_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(b_test_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(m_test_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image size and channels\n",
    "img_channels = 3\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "# number of classes\n",
    "b_nb_classes = 2\n",
    "m_nb_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Divide data into batches and process them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: prepare and process batch wise data for training/ablation. \n",
    "The image path is converted to image data while the classes are label encoded (0,1,2)\n",
    "input:\n",
    "    i.image_list: X data: array of image paths\n",
    "    ii:classes: y data: dictionary of image paths and their corresponding classes\n",
    "output:\n",
    "    i. DataGenerator\n",
    "'''\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, image_list, classes, batch_size=10, dim=(224,224), n_channels=3,\n",
    "                 n_classes=3,shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.classes = classes\n",
    "        self.image_list = image_list\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.image_list) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_img_temp = [self.image_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_img_temp)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.image_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_img_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization of Y\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        #X = np.random.rand(self.batch_size, *self.dim, self.n_channels)\n",
    "\n",
    "        #For each image path in the batch: load it, convert it to array, normalize values and pre-process.\n",
    "        #Append X and respective y values to the empty X and y variables\n",
    "        for i, ID in enumerate(list_img_temp):\n",
    "            img = load_img(ID, target_size=self.dim)\n",
    "            img = img_to_array(img)\n",
    "            #img = img/255\n",
    "            #process = datagen.fit(img)\n",
    "            img = preprocess_input(img)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            X[i,] = img\n",
    "            y[i] = self.classes[ID]\n",
    "            \n",
    "        #class encoding to 0,1,2\n",
    "#         le = LabelEncoder()\n",
    "#         self.y_value = le.fit_transform(y)\n",
    "        return X,keras.utils.to_categorical(y, num_classes=self.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: get the data generators for training and validation\n",
    "input:\n",
    "    i.train_X, test_X: array of image paths in training and testing respectively\n",
    "    ii.train_set, test_set: dictionary of image paths and their corresponding class for training and test data respectively\n",
    "    iii. ablation: int: number of training and test entries to use for DataGeneration\n",
    "output:\n",
    "    i. training_generator\n",
    "    ii. validation_generator\n",
    "'''\n",
    "def data_generator(train_X, train_set, test_X, test_set,classes,ablation = None):\n",
    "    #Randomly selecting data in case of ablation testing\n",
    "    if ablation != None:\n",
    "        train_X = random.sample(train_X, ablation)\n",
    "        train_set = {image: train_set[image] for image in train_X }\n",
    "        test_X = random.sample(test_X, ablation)\n",
    "        test_set = {image: test_set[image] for image in test_X }\n",
    "    print(Counter(test_set.values()))\n",
    "    print(Counter(train_set.values()))\n",
    "    training_generator = DataGenerator(train_X, train_set,n_classes=classes)\n",
    "    validation_generator = DataGenerator(test_X, test_set,n_classes=classes)\n",
    "    return training_generator,validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 51, 1: 49})\n",
      "Counter({1: 51, 0: 49})\n"
     ]
    }
   ],
   "source": [
    "training_generator, validation_generator = data_generator(b_train_X, b_train_set, b_test_X, b_test_set,classes=b_nb_classes,ablation=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet',include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = Model(inputs=base_model.input, outputs=base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in res_model.layers:\n",
    "#         layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resNetModel_base():\n",
    "#     # base resNet model\n",
    "#     base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "#     x = base_model.output\n",
    "#     x = GlobalAveragePooling2D()(x)\n",
    "#     x = Dense(1024, activation='relu')(x)\n",
    "#     prediction = Dense(2, activation='softmax')(x)\n",
    "#     model = Model(inputs=base_model.input, outputs=x)\n",
    "#     for layer in model.layers[:-5]:\n",
    "#         layer.trainable = True\n",
    "#     return model\n",
    "\n",
    "# #call define model\n",
    "# res_model = resNetModel_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = random.sample(b_train_X, 200)\n",
    "train_set = {image: b_train_set[image] for image in b_train_X }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_X = random.sample(b_test_X, 100)\n",
    "# test_set = {image: b_test_set[image] for image in b_test_X }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeatureExtraction(train_X, train_set):\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for i, image_path in enumerate(train_X):\n",
    "        img = image.load_img(image_path, target_size=(224,224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        #img = img/255\n",
    "        img = np.expand_dims(img_array, axis=0)\n",
    "        img_process = preprocess_input(img)\n",
    "        feature = vgg_model.predict(img_process)\n",
    "        flat = feature.flatten()\n",
    "        features.append(flat)\n",
    "        label = train_set[image_path]\n",
    "        labels.append(label)\n",
    "        if (i % 100) == 0:\n",
    "            print('On image',i)\n",
    "            #print(img_process)\n",
    "    le = LabelEncoder()\n",
    "    y_value = le.fit_transform(labels)\n",
    "    return features, y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On image 0\n",
      "On image 100\n",
      "On image 200\n",
      "On image 300\n",
      "On image 400\n",
      "On image 500\n",
      "On image 600\n",
      "On image 700\n",
      "On image 800\n",
      "On image 900\n",
      "On image 1000\n",
      "On image 1100\n",
      "On image 1200\n",
      "On image 1300\n",
      "On image 1400\n",
      "On image 1500\n",
      "On image 1600\n",
      "On image 1700\n",
      "On image 1800\n",
      "On image 1900\n",
      "On image 2000\n",
      "On image 2100\n",
      "On image 2200\n",
      "On image 2300\n",
      "On image 2400\n",
      "On image 2500\n",
      "On image 2600\n",
      "On image 2700\n",
      "On image 2800\n",
      "On image 2900\n",
      "On image 3000\n",
      "On image 3100\n",
      "On image 3200\n",
      "On image 3300\n",
      "On image 3400\n",
      "On image 3500\n",
      "On image 3600\n",
      "On image 3700\n",
      "On image 3800\n",
      "On image 3900\n",
      "On image 4000\n",
      "On image 4100\n",
      "On image 4200\n",
      "On image 4300\n",
      "On image 4400\n",
      "On image 4500\n",
      "On image 4600\n",
      "On image 4700\n",
      "On image 4800\n",
      "On image 4900\n",
      "On image 5000\n",
      "On image 5100\n",
      "On image 5200\n",
      "On image 5300\n",
      "On image 5400\n",
      "On image 5500\n",
      "On image 5600\n"
     ]
    }
   ],
   "source": [
    "features, labels = FeatureExtraction(b_train_X, b_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary VGG SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=100, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='rbf', max_iter=1000, C=100, gamma=0.001, class_weight='balanced'))])\n",
    "pipe.fit(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7230055327503123"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(features,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On image 0\n",
      "On image 100\n"
     ]
    }
   ],
   "source": [
    "t_features, t_labels = FeatureExtraction(train_X, train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loocv = model_selection.LeaveOneOut()\n",
    "# results = model_selection.cross_val_score(pipe, features, labels, cv=loocv)\n",
    "# print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a KFold object with 5 splits \n",
    "# folds = KFold(n_splits = 5, shuffle = True, random_state = 101)\n",
    "\n",
    "# # specify range of hyperparameters\n",
    "# # Set the parameters by cross-validation\n",
    "# hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# # specify model\n",
    "# sc = StandardScaler()\n",
    "# data = sc.fit_transform(t_features)\n",
    "# svc = SVC(kernel='sigmoid', class_weight='balanced')\n",
    "\n",
    "# # set up GridSearchCV()\n",
    "# model_cv = GridSearchCV(estimator = svc, \n",
    "#                         param_grid = hyper_params, \n",
    "#                         scoring= 'accuracy', \n",
    "#                         cv = folds, \n",
    "#                         verbose = 1,\n",
    "#                         return_train_score=True)      \n",
    "\n",
    "# # fit the model\n",
    "# model_cv.fit(data,t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.737877</td>\n",
       "      <td>0.004806</td>\n",
       "      <td>0.177348</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.046368</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.739920</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.179598</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.046368</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.740756</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.176740</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.052440</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99375</td>\n",
       "      <td>0.99375</td>\n",
       "      <td>0.99375</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99625</td>\n",
       "      <td>0.003062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.743207</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.180751</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.046368</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.759984</td>\n",
       "      <td>0.022659</td>\n",
       "      <td>0.181829</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.046368</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       0.737877      0.004806         0.177348        0.004338       1   \n",
       "1       0.739920      0.002667         0.179598        0.003138       1   \n",
       "2       0.740756      0.008089         0.176740        0.002345       1   \n",
       "3       0.743207      0.005280         0.180751        0.002113      10   \n",
       "4       0.759984      0.022659         0.181829        0.001968      10   \n",
       "\n",
       "  param_gamma                     params  split0_test_score  \\\n",
       "0        0.01    {'C': 1, 'gamma': 0.01}              0.550   \n",
       "1       0.001   {'C': 1, 'gamma': 0.001}              0.550   \n",
       "2      0.0001  {'C': 1, 'gamma': 0.0001}              0.625   \n",
       "3        0.01   {'C': 10, 'gamma': 0.01}              0.550   \n",
       "4       0.001  {'C': 10, 'gamma': 0.001}              0.550   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0              0.550               0.45       ...                   0.540   \n",
       "1              0.550               0.45       ...                   0.540   \n",
       "2              0.475               0.50       ...                   0.525   \n",
       "3              0.550               0.45       ...                   0.540   \n",
       "4              0.550               0.45       ...                   0.540   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.046368                1                 1.0             1.00000   \n",
       "1        0.046368                1                 1.0             1.00000   \n",
       "2        0.052440                9                 1.0             0.99375   \n",
       "3        0.046368                1                 1.0             1.00000   \n",
       "4        0.046368                1                 1.0             1.00000   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             1.00000             1.00000                 1.0   \n",
       "1             1.00000             1.00000                 1.0   \n",
       "2             0.99375             0.99375                 1.0   \n",
       "3             1.00000             1.00000                 1.0   \n",
       "4             1.00000             1.00000                 1.0   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0           1.00000         0.000000  \n",
       "1           1.00000         0.000000  \n",
       "2           0.99625         0.003062  \n",
       "3           1.00000         0.000000  \n",
       "4           1.00000         0.000000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.40, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.4, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.4, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best test score is 0.54 corresponding to hyperparameters {'C': 1, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# printing the optimal accuracy score and hyperparameters\n",
    "best_score = model_cv.best_score_\n",
    "best_hyperparams = model_cv.best_params_\n",
    "\n",
    "print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(best_score, best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=50).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=1000, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='poly',\n",
       "  max_iter=50, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='poly', max_iter=50,\n",
    "                                                            C=1000,\n",
    "                                                            gamma = 0.1, class_weight='balanced'\n",
    "                                                           ))])\n",
    "final.fit(t_features,t_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### Binary Base Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On image 0\n"
     ]
    }
   ],
   "source": [
    "b_test_feature, b_test_labels = FeatureExtraction(b_test_X, b_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-618f09e3c94a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbinary_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_test_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#binary_y_pred = final.predict(b_test_feature)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "binary_y_pred = pipe.predict(b_test_feature)\n",
    "#binary_y_pred = final.predict(b_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 96, 0: 4})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(binary_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Test Score  0.51\n"
     ]
    }
   ],
   "source": [
    "binary_score_test = metrics.accuracy_score(b_test_labels, binary_y_pred)\n",
    "print('Base Model Test Score ',binary_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2 47]\n",
      " [ 2 49]]\n"
     ]
    }
   ],
   "source": [
    "binary_cm = confusion_matrix(b_test_labels, binary_y_pred)\n",
    "print(binary_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.04      0.08        49\n",
      "          1       0.51      0.96      0.67        51\n",
      "\n",
      "avg / total       0.51      0.51      0.38       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_report = classification_report(b_test_labels,binary_y_pred)\n",
    "print(binary_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5008003201280512"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(b_test_labels, binary_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Base Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_train_X = random.sample(m_train_X, 200)\n",
    "# m_train_set = {image: m_train_set[image] for image in m_train_X }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On image 0\n",
      "On image 100\n",
      "On image 200\n",
      "On image 300\n",
      "On image 400\n",
      "On image 500\n",
      "On image 600\n",
      "On image 700\n",
      "On image 800\n",
      "On image 900\n",
      "On image 1000\n",
      "On image 1100\n",
      "On image 1200\n",
      "On image 1300\n",
      "On image 1400\n",
      "On image 1500\n",
      "On image 1600\n",
      "On image 1700\n",
      "On image 1800\n",
      "On image 1900\n",
      "On image 2000\n",
      "On image 2100\n",
      "On image 2200\n",
      "On image 2300\n",
      "On image 2400\n",
      "On image 2500\n",
      "On image 2600\n",
      "On image 2700\n",
      "On image 2800\n",
      "On image 2900\n",
      "On image 3000\n",
      "On image 3100\n",
      "On image 3200\n",
      "On image 3300\n",
      "On image 3400\n",
      "On image 3500\n",
      "On image 3600\n",
      "On image 3700\n",
      "On image 3800\n",
      "On image 3900\n",
      "On image 4000\n",
      "On image 4100\n",
      "On image 4200\n"
     ]
    }
   ],
   "source": [
    "m_features, m_labels = FeatureExtraction(m_train_X, m_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class ResNet SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:218: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svc', SVC(C=100, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=1000, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='rbf', max_iter=1000, C=100, gamma=0.001, class_weight='balanced'))])\n",
    "m_pipe.fit(m_features,m_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87461337140138"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_pipe.score(m_features,m_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating a KFold object with 5 splits \n",
    "# folds = KFold(n_splits = 5, shuffle = True, random_state = 101)\n",
    "\n",
    "# # specify range of hyperparameters\n",
    "# # Set the parameters by cross-validation\n",
    "# hyper_params = [ {'gamma': [1e-2, 1e-3, 1e-4],\n",
    "#                      'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "\n",
    "# # specify model\n",
    "# sc = StandardScaler()\n",
    "# m_data = sc.fit_transform(m_features)\n",
    "# m_svc = SVC(kernel='rbf')\n",
    "\n",
    "# # set up GridSearchCV()\n",
    "# m_model_cv = GridSearchCV(estimator = m_svc, \n",
    "#                         param_grid = hyper_params, \n",
    "#                         scoring= 'accuracy', \n",
    "#                         cv = folds, \n",
    "#                         verbose = 1,\n",
    "#                         return_train_score=True)      \n",
    "\n",
    "# # fit the model\n",
    "# m_model_cv.fit(m_data,m_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_cv_results = pd.DataFrame(m_model_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # converting C to numeric type for plotting on x-axis\n",
    "# m_cv_results['param_C'] = m_cv_results['param_C'].astype('int')\n",
    "\n",
    "# # # plotting\n",
    "# plt.figure(figsize=(16,6))\n",
    "\n",
    "# # subplot 1/3\n",
    "# plt.subplot(131)\n",
    "# gamma_01 = m_cv_results[m_cv_results['param_gamma']==0.01]\n",
    "\n",
    "# plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "# plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title(\"Gamma=0.01\")\n",
    "# plt.ylim([0.40, 1])\n",
    "# plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "# plt.xscale('log')\n",
    "\n",
    "# # subplot 2/3\n",
    "# plt.subplot(132)\n",
    "# gamma_001 = m_cv_results[m_cv_results['param_gamma']==0.001]\n",
    "\n",
    "# plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "# plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title(\"Gamma=0.001\")\n",
    "# plt.ylim([0.4, 1])\n",
    "# plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "# plt.xscale('log')\n",
    "\n",
    "\n",
    "# # subplot 3/3\n",
    "# plt.subplot(133)\n",
    "# gamma_0001 = m_cv_results[m_cv_results['param_gamma']==0.0001]\n",
    "\n",
    "# plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "# plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "# plt.xlabel('C')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title(\"Gamma=0.0001\")\n",
    "# plt.ylim([0.4, 1])\n",
    "# plt.legend(['test accuracy', 'train accuracy'], loc='upper left')\n",
    "# plt.xscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # printing the optimal accuracy score and hyperparameters\n",
    "# m_best_score = m_model_cv.best_score_\n",
    "# m_best_hyperparams = m_model_cv.best_params_\n",
    "\n",
    "# print(\"The best test score is {0} corresponding to hyperparameters {1}\".format(m_best_score, m_best_hyperparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_final = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel='rbf', max_iter=50,\n",
    "#                                                             C=m_best_hyperparams['C'],\n",
    "#                                                             gamma = m_best_hyperparams['gamma']\n",
    "#                                                            ))])\n",
    "# m_final.fit(m_features,m_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Res Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_test_X = random.sample(m_test_X, 100)\n",
    "# m_test_set = {image: m_test_set[image] for image in m_test_X }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On image 0\n",
      "On image 100\n",
      "On image 200\n",
      "On image 300\n",
      "On image 400\n",
      "On image 500\n",
      "On image 600\n",
      "On image 700\n",
      "On image 800\n",
      "On image 900\n",
      "On image 1000\n",
      "On image 1100\n",
      "On image 1200\n",
      "On image 1300\n",
      "On image 1400\n",
      "On image 1500\n",
      "On image 1600\n",
      "On image 1700\n"
     ]
    }
   ],
   "source": [
    "m_test_feature, m_test_labels = FeatureExtraction(m_test_X, m_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_y_pred = m_pipe.predict(m_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1583, 2: 90, 1: 124})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(multi_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Test Score  0.39621591541457984\n"
     ]
    }
   ],
   "source": [
    "multi_score_test = metrics.accuracy_score(m_test_labels, multi_y_pred)\n",
    "print('Base Model Test Score ',multi_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[554  24  21]\n",
      " [500  94   5]\n",
      " [529   6  64]]\n"
     ]
    }
   ],
   "source": [
    "multi_cm = confusion_matrix(m_test_labels, multi_y_pred)\n",
    "print(multi_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.35      0.92      0.51       599\n",
      "          1       0.76      0.16      0.26       599\n",
      "          2       0.71      0.11      0.19       599\n",
      "\n",
      "avg / total       0.61      0.40      0.32      1797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_report = classification_report(m_test_labels,multi_y_pred)\n",
    "print(multi_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"vgg_svm_binary.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(m_pipe, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_filename = \"vgg_svm_multi.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(m_pipe, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickle_model = pickle.load(file)\n",
    "    \n",
    "# Calculate the accuracy score and predict target values\n",
    "Ypredict = pickle_model.predict(m_test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_score_test = metrics.accuracy_score(m_test_labels, Ypredict)\n",
    "print('Base Model Test Score ',multi_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
