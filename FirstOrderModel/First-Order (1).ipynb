{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: First Order Model\n",
    "\n",
    "**Objective**: Leverage the DeepFake generator model to improve the performance of DeepFake detection models\n",
    "\n",
    "**Hypothesis**: The hypothesis behind the model is that generator models have robust feature extraction, which if leveraged can lead to a significant improvement in the DeepFake detection accuracy\n",
    "\n",
    "**Notebook Division**:\n",
    "1. Binary Classification\n",
    "2. Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the relevant code for First Order Model Animation\n",
    "# !git clone https://github.com/AliaksandrSiarohin/first-order-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -U scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/project/first-order-model\n"
     ]
    }
   ],
   "source": [
    "cd first-order-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#Data processing\n",
    "from skimage import io\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "#Feature Extraction\n",
    "from demo import load_checkpoints\n",
    "import torch\n",
    "\n",
    "# Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Neural Network\n",
    "import keras\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your dataset\n",
    "DATASET_PATH = '/mnt/disks/user/project/Dataset/'\n",
    "deepfake_class = ['FaceSwap/clean_frames', 'Reenactment/clean_frames','original/clean_frames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: load the deepfake dataset and divide them into train and test with each having samples of the different classes\n",
    "input:\n",
    "    i.dataset_path: string: the main dataset folder path \n",
    "    ii.train_ratio: float: the ratio of the dataset that will be used for training the model. Eg: 0.8\n",
    "    iii. fake_class: string array: the different deepfake classes\n",
    "output:\n",
    "    i. train_set, test_set: dictionary of image paths as key and deepfake class as value\n",
    "    ii. X_train, X_test: array of image paths \n",
    "    iii. y_train, y_test: array of corresponding deepfake classes \n",
    "'''\n",
    "def MultiDatasetSplit(DATASET_PATH, train_ratio,fake_cls):\n",
    "    test_set = {}\n",
    "    train_set = {}\n",
    "    list_IDs = []\n",
    "    labels = {}\n",
    "    for i, cls in enumerate(fake_cls):\n",
    "        paths = glob.glob(os.path.join(DATASET_PATH, cls,'*/*.jpg'))\n",
    "        #balancing the dataset\n",
    "        balance_paths = random.sample(paths,2000)\n",
    "\n",
    "        brk_point = int(len(balance_paths)*train_ratio)\n",
    "        for j in range(len(balance_paths)):\n",
    "            if j <= brk_point:\n",
    "                train_set.update({balance_paths[j]:i})\n",
    "            else:\n",
    "                test_set.update({balance_paths[j]:i})\n",
    "    \n",
    "    X_train = [X for X in train_set.keys()] \n",
    "    y_train = [y for y in train_set.values()]\n",
    "    X_test = [X for X in test_set.keys()]\n",
    "    y_test = [y for y in test_set.values()]\n",
    "    return train_set, test_set, X_train,y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: load the deepfake dataset and divide them into train and test with each having samples of the different classes\n",
    "input:\n",
    "    i.dataset_path: string: the main dataset folder path \n",
    "    ii.train_ratio: float: the ratio of the dataset that will be used for training the model. Eg: 0.8\n",
    "    iii. fake_class: string array: the different deepfake classes\n",
    "output:\n",
    "    i. train_set, test_set: dictionary of image paths as key and deepfake class as value\n",
    "    ii. X_train, X_test: array of image paths \n",
    "    iii. y_train, y_test: array of corresponding deepfake classes \n",
    "'''\n",
    "def BinaryDatasetSplit(DATASET_PATH, train_ratio,fake_cls):\n",
    "    test_set = {}\n",
    "    train_set = {}\n",
    "    list_IDs = []\n",
    "    labels = {}\n",
    "    for i, cls in enumerate(fake_cls):\n",
    "        paths = glob.glob(os.path.join(DATASET_PATH, cls,'*/*.jpg'))\n",
    "        if i == 0:\n",
    "            paths = random.sample(paths,4000)\n",
    "        else:\n",
    "            paths = random.sample(paths,2000)\n",
    "        brk_point = int(len(paths)*train_ratio)\n",
    "        for j in range(len(paths)):\n",
    "            if j <= brk_point:\n",
    "                if i == 0:\n",
    "                    train_set.update({paths[j]:0})\n",
    "                else: \n",
    "                    train_set.update({paths[j]:1})\n",
    "            else:\n",
    "                if i == 0:\n",
    "                    test_set.update({paths[j]:0})\n",
    "                else:\n",
    "                    test_set.update({paths[j]:1})\n",
    "\n",
    "    X_train = [X for X in train_set.keys()] \n",
    "    y_train = [y for y in train_set.values()]\n",
    "    X_test = [X for X in test_set.keys()]\n",
    "    y_test = [y for y in test_set.values()]\n",
    "    return train_set, test_set, X_train,y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_train_set, b_test_set, b_train_X, b_train_y, b_test_X, b_test_y = BinaryDatasetSplit(DATASET_PATH,0.7,deepfake_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train_set, m_test_set, m_train_X, m_train_y, m_test_X, m_test_y = MultiDatasetSplit(DATASET_PATH,0.7,deepfake_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2801, 1: 2802})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(b_train_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 1401, 1: 1401, 2: 1401})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(m_train_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(b_test_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(m_test_set.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify image size and channels\n",
    "img_channels = 3\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "\n",
    "# number of classes\n",
    "b_nb_classes = 2\n",
    "m_nb_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Allow for batch-wise pre-processing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: prepare and process batch wise data for training/ablation. \n",
    "The image path is converted to image data while the classes are label encoded (0,1,2)\n",
    "input:\n",
    "    i.image_list: X data: array of image paths\n",
    "    ii.classes: y data: dictionary of image paths and their corresponding classes\n",
    "    iii. feature_extractor model: model used to feature extraction in batches\n",
    "output:\n",
    "    i. DataGenerator\n",
    "'''\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, image_list, classes, feature_extractor, batch_size=32, dim=(256,256), n_channels=3,\n",
    "                 n_classes=3,shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.classes = classes\n",
    "        self.image_list = image_list\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.image_list) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_img_temp = [self.image_list[k] for k in indexes]\n",
    "        #print(list_img_temp)\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_img_temp)\n",
    "        #print(X,y)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.image_list))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_img_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization of Y\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "\n",
    "        #For each image path in the batch: load it, convert it to array, normalize values and pre-process.\n",
    "        #Append X and respective y values to the empty X and y variables\n",
    "        for i, ID in enumerate(list_img_temp):\n",
    "            img = image.load_img(ID, target_size=self.dim)\n",
    "            img = image.img_to_array(img)\n",
    "            #img = img/255\n",
    "            img = preprocess_input(img)\n",
    "            X[i,] = img\n",
    "            y[i] = self.classes[ID]\n",
    "            \n",
    "        #Extract features for batch-wise values\n",
    "        output = torch.tensor(X, dtype=torch.float).to('cuda')\n",
    "        output_val = encoder(output)\n",
    "        feature = output_val.cpu().data.numpy().reshape(32,256,256,-1)\n",
    "        #class encoding to 0,1,2\n",
    "        le = LabelEncoder()\n",
    "        self.y_value = le.fit_transform(y)\n",
    "        return feature,y_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: get the data generators for training and validation\n",
    "input:\n",
    "    i.train_X, test_X: array of image paths in training and testing respectively\n",
    "    ii.train_set, test_set: dictionary of image paths and their corresponding class for training and test data respectively\n",
    "    iii. ablation: int: number of training and test entries to use for DataGeneration\n",
    "output:\n",
    "    i. training_generator\n",
    "    ii. validation_generator\n",
    "'''\n",
    "def data_generator(train_X, train_set, test_X, test_set,feature_model,ablation = None):\n",
    "    #Randomly selecting data in case of ablation testing\n",
    "    if ablation != None:\n",
    "        train_X = random.sample(train_X, ablation)\n",
    "        train_set = {image: train_set[image] for image in train_X }\n",
    "        test_X = random.sample(test_X, ablation)\n",
    "        test_set = {image: test_set[image] for image in test_X }\n",
    "    training_generator = DataGenerator(train_X, train_set,feature_model)\n",
    "    validation_generator = DataGenerator(test_X, test_set,feature_model)\n",
    "    return training_generator,validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: process the image paths to return image values and respective labeled classes\n",
    "input:\n",
    "    i.batch_X: array of image paths \n",
    "    ii.batch_y: dictionary of image paths and their corresponding class\n",
    "output:\n",
    "    i. X: processed image data\n",
    "    ii. y_value: corresponding class values\n",
    "'''\n",
    "def PreProcess(batch_X, batch_y, batch_size=32, dimension=(256,256), n_channels=3):\n",
    "    X = np.empty((len(batch_X), *dimension, n_channels))\n",
    "    y = np.empty((len(batch_X)), dtype=int)\n",
    "    for i, image_path in enumerate(batch_X):\n",
    "        img = image.load_img(image_path, target_size=dimension)\n",
    "        img = image.img_to_array(img)\n",
    "        #img = img/255\n",
    "        img = preprocess_input(img)\n",
    "        X[i,] = img\n",
    "        y[i] = batch_y[image_path]\n",
    "    le = LabelEncoder()\n",
    "    y_value = le.fit_transform(y)\n",
    "    return X,y_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "Load model and model checkpoints for Vox (from the other dataset models, Vox appears to be the most relevant and closest in content to the FaceForensics++ Dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path='config/vox-256.yaml' #data checkpoints\n",
    "checkpoint_path='../vox-cpk.pth.tar' #pyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kp_detector model loads keypoints\n",
    "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml', \n",
    "                            checkpoint_path='../vox-cpk.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dir(generator.module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(generator.module.down_blocks)\n",
    "#encoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (r0): ResBlock2d(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (r1): ResBlock2d(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (r2): ResBlock2d(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (r3): ResBlock2d(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (r4): ResBlock2d(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (r5): ResBlock2d(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm1): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (norm2): SynchronizedBatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the pre-trained weights from the generator module\n",
    "encoder = generator.module.bottleneck\n",
    "encoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: extract features from the pre-trained segment of the generator\n",
    "input:\n",
    "    i.model: pre-trained feature extraction model\n",
    "    ii.X_batch: pre-processed batch of image data arrays\n",
    "output:\n",
    "    i. output: array: feature extracted values for X images\n",
    "'''\n",
    "def feature_model(model, X_batch):\n",
    "    data = torch.tensor(X_batch, dtype=torch.float).to('cuda')\n",
    "    output = encoder(data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class roc_callback(Callback):\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs['val_auc'] = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_p = []\n",
    "        y_v = []\n",
    "        for i in range(len(validation_generator)):\n",
    "            x_val, y_val = validation_generator[i]\n",
    "            y_pred = self.model.predict(x_val)\n",
    "            y_p.append(y_pred)\n",
    "            y_v.append(y_val)\n",
    "        y_p = np.concatenate(y_p)\n",
    "        y_v = np.concatenate(y_v)\n",
    "        roc_auc = roc_auc_score(y_v, y_p)\n",
    "        print ('\\nVal AUC for epoch{}: {}'.format(epoch, roc_auc))\n",
    "        logs['val_auc'] = roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model\n",
    "\n",
    "Test Different Classification Models for Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: CNN model for DeepFake classification \n",
    "'''\n",
    "def CNN_Model(in_shape=(256,256,3)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3), strides=(2,2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(b_nb_classes, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "#call define model\n",
    "binary_first_model = CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.005, momentum=0.5, decay = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator, validation_generator = data_generator(b_train_X, b_train_set, b_test_X, b_test_set,encoder)\n",
    "binary_first_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "174/175 [============================>.] - ETA: 1s - loss: 7.9276 - acc: 0.5047\n",
      "Epoch 00001: val_acc improved from -inf to 0.50042, saving model to /mnt/disks/user/project/Final_Models/first_order_binary_best_modelv2.hdf5\n",
      "\n",
      "Val AUC for epoch0: 0.5025216588020873\n",
      "175/175 [==============================] - 297s 2s/step - loss: 7.9266 - acc: 0.5047 - val_loss: 8.0078 - val_acc: 0.5004\n",
      "Epoch 2/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.8938 - acc: 0.5075\n",
      "Epoch 00002: val_acc improved from 0.50042 to 0.51858, saving model to /mnt/disks/user/project/Final_Models/first_order_binary_best_modelv2.hdf5\n",
      "\n",
      "Val AUC for epoch1: 0.519083490269931\n",
      "175/175 [==============================] - 109s 624ms/step - loss: 7.8973 - acc: 0.5072 - val_loss: 7.7074 - val_acc: 0.5186\n",
      "Epoch 3/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.7538 - acc: 0.5158\n",
      "Epoch 00003: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch2: 0.5007914597956971\n",
      "175/175 [==============================] - 105s 601ms/step - loss: 7.7353 - acc: 0.5170 - val_loss: 8.0345 - val_acc: 0.4987\n",
      "Epoch 4/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.9537 - acc: 0.5038\n",
      "Epoch 00004: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch3: 0.5010108143582721\n",
      "175/175 [==============================] - 106s 607ms/step - loss: 7.9684 - acc: 0.5029 - val_loss: 8.0243 - val_acc: 0.4994\n",
      "Epoch 5/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.9753 - acc: 0.5024\n",
      "Epoch 00005: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch4: 0.5010108143582721\n",
      "175/175 [==============================] - 107s 612ms/step - loss: 7.9712 - acc: 0.5027 - val_loss: 8.0243 - val_acc: 0.4994\n",
      "Epoch 6/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.9796 - acc: 0.5022\n",
      "Epoch 00006: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch5: 0.5006334459459459\n",
      "175/175 [==============================] - 107s 610ms/step - loss: 7.9683 - acc: 0.5029 - val_loss: 8.0243 - val_acc: 0.4994\n",
      "Epoch 7/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.9841 - acc: 0.5019\n",
      "Epoch 00007: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch6: 0.5000019616850804\n",
      "175/175 [==============================] - 107s 609ms/step - loss: 7.9871 - acc: 0.5017 - val_loss: 8.0113 - val_acc: 0.5002\n",
      "Epoch 8/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0048 - acc: 0.5006\n",
      "Epoch 00008: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch7: 0.5000019616850804\n",
      "175/175 [==============================] - 106s 608ms/step - loss: 8.0020 - acc: 0.5008 - val_loss: 8.0113 - val_acc: 0.5002\n",
      "Epoch 9/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.9962 - acc: 0.5012\n",
      "Epoch 00009: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch8: 0.5002009848435671\n",
      "175/175 [==============================] - 106s 608ms/step - loss: 8.0077 - acc: 0.5004 - val_loss: 8.0113 - val_acc: 0.5002\n",
      "Epoch 10/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0120 - acc: 0.5002\n",
      "Epoch 00010: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch9: 0.5002173905289777\n",
      "175/175 [==============================] - 107s 614ms/step - loss: 8.0091 - acc: 0.5004 - val_loss: 8.0283 - val_acc: 0.4992\n",
      "Epoch 11/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0077 - acc: 0.5004\n",
      "Epoch 00011: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch10: 0.5002173905289777\n",
      "175/175 [==============================] - 106s 608ms/step - loss: 8.0077 - acc: 0.5004 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 12/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0034 - acc: 0.5007\n",
      "Epoch 00012: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch11: 0.5002173905289777\n",
      "175/175 [==============================] - 106s 603ms/step - loss: 8.0034 - acc: 0.5007 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 13/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.9990 - acc: 0.5010\n",
      "Epoch 00013: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch12: 0.5002173905289777\n",
      "175/175 [==============================] - 106s 607ms/step - loss: 8.0077 - acc: 0.5004 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 14/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0077 - acc: 0.5004\n",
      "Epoch 00014: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch13: 0.5002173905289777\n",
      "175/175 [==============================] - 106s 605ms/step - loss: 8.0034 - acc: 0.5007 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 15/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0048 - acc: 0.5006\n",
      "Epoch 00015: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch14: 0.5002173905289777\n",
      "175/175 [==============================] - 106s 605ms/step - loss: 8.0063 - acc: 0.5005 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 16/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0062 - acc: 0.5005\n",
      "Epoch 00016: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch15: 0.5002173905289777\n",
      "175/175 [==============================] - 105s 602ms/step - loss: 8.0092 - acc: 0.5004 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 17/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0077 - acc: 0.5004\n",
      "Epoch 00017: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch16: 0.5002173905289777\n",
      "175/175 [==============================] - 105s 600ms/step - loss: 8.0092 - acc: 0.5004 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 18/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 8.0221 - acc: 0.4996\n",
      "Epoch 00018: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch17: 0.5002173905289777\n",
      "175/175 [==============================] - 105s 599ms/step - loss: 8.0106 - acc: 0.5003 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 19/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.9904 - acc: 0.5015\n",
      "Epoch 00019: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch18: 0.5001968840951891\n",
      "175/175 [==============================] - 107s 609ms/step - loss: 8.0034 - acc: 0.5007 - val_loss: 8.0012 - val_acc: 0.5008\n",
      "Epoch 20/20\n",
      "174/175 [============================>.] - ETA: 0s - loss: 7.9947 - acc: 0.5013\n",
      "Epoch 00020: val_acc did not improve from 0.51858\n",
      "\n",
      "Val AUC for epoch19: 0.5002009848435671\n",
      "175/175 [==============================] - 106s 606ms/step - loss: 8.0063 - acc: 0.5005 - val_loss: 8.0350 - val_acc: 0.4987\n"
     ]
    }
   ],
   "source": [
    "# checkpoint \n",
    "binary_filepath = '/mnt/disks/user/project/Final_Models/first_order_binary_best_modelv2.hdf5'\n",
    "checkpoint = ModelCheckpoint(binary_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "auc_logger = roc_callback()\n",
    "# fit: this will fit the net on 'ablation' samples, only 1 epoch\n",
    "binary_history = binary_first_model.fit_generator(generator = training_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    shuffle=True,\n",
    "                    epochs=20,\n",
    "                    callbacks=[checkpoint,auc_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7ff2db62b198>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_acc = binary_history.history['acc']\n",
    "binary_val_acc = binary_history.history['val_acc']\n",
    "\n",
    "binary_epochs = range(len(binary_acc))\n",
    "\n",
    "plt.plot(binary_epochs, binary_acc, 'g', label='Training acc')\n",
    "plt.plot(binary_epochs, binary_val_acc, 'b', label='Validation acc')\n",
    "plt.title('Binary Classification Res Model Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary First Order Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_test_generator = DataGenerator(b_test_X, b_test_set,encoder,n_classes=2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_eval_base_model = load_model(binary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = binary_eval_base_model.predict_generator(binary_test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_y_class = np.array(list(binary_test_generator.classes.values()))[:len(binary_predictions)]\n",
    "binary_y = keras.utils.to_categorical(binary_y_class, num_classes=b_nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_prob_max = binary_predictions.max(axis=1).reshape(-1, 1)\n",
    "binary_y_pred = np.where(binary_predictions == binary_prob_max, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_pred = np.argmax(binary_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res Model Test Score  0.40244932432432434\n"
     ]
    }
   ],
   "source": [
    "binary_score_test = metrics.accuracy_score(binary_y, binary_y_pred)\n",
    "print('Res Model Test Score ',binary_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[311 888]\n",
      " [216 953]]\n"
     ]
    }
   ],
   "source": [
    "binary_cm = confusion_matrix(binary_y_class, binary_pred)\n",
    "print(binary_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.26      0.36      1199\n",
      "          1       0.49      1.00      0.66      1169\n",
      "\n",
      "avg / total       0.54      0.62      0.51      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "binary_report = classification_report(binary_y,binary_y_pred)\n",
    "print(binary_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5186523771235083"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(binary_y, binary_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "func: CNN model for DeepFake classification \n",
    "'''\n",
    "def CNN_Model(in_shape=(256,256,3)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64,(3,3), strides=(2,2), padding='same', input_shape=in_shape))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(m_nb_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "#call define model\n",
    "multi_first_model = CNN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.005, momentum=0.5, decay = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator, validation_generator = data_generator(m_train_X, m_train_set, m_test_X, m_test_set,encoder)\n",
    "multi_first_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "130/131 [============================>.] - ETA: 1s - loss: 7.0125 - acc: 0.5622\n",
      "Epoch 00001: val_acc improved from -inf to 0.55357, saving model to /mnt/disks/user/project/Final_Models/first_order_multi_best_modelv2.hdf5\n",
      "\n",
      "Val AUC for epoch0: 0.49762182604391897\n",
      "131/131 [==============================] - 267s 2s/step - loss: 7.0099 - acc: 0.5623 - val_loss: 7.1564 - val_acc: 0.5536\n",
      "Epoch 2/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.0902 - acc: 0.5577\n",
      "Epoch 00002: val_acc improved from 0.55357 to 0.55580, saving model to /mnt/disks/user/project/Final_Models/first_order_multi_best_modelv2.hdf5\n",
      "\n",
      "Val AUC for epoch1: 0.5\n",
      "131/131 [==============================] - 87s 667ms/step - loss: 7.0947 - acc: 0.5574 - val_loss: 7.1206 - val_acc: 0.5558\n",
      "Epoch 3/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1340 - acc: 0.5550\n",
      "Epoch 00003: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch2: 0.5\n",
      "131/131 [==============================] - 91s 693ms/step - loss: 7.1254 - acc: 0.5555 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 4/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1211 - acc: 0.5558\n",
      "Epoch 00004: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch3: 0.5\n",
      "131/131 [==============================] - 83s 636ms/step - loss: 7.1203 - acc: 0.5558 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 5/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1288 - acc: 0.5553\n",
      "Epoch 00005: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch4: 0.5\n",
      "131/131 [==============================] - 84s 638ms/step - loss: 7.1203 - acc: 0.5558 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 6/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1211 - acc: 0.5558\n",
      "Epoch 00006: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch5: 0.5\n",
      "131/131 [==============================] - 83s 635ms/step - loss: 7.1229 - acc: 0.5557 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 7/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1442 - acc: 0.5543\n",
      "Epoch 00007: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch6: 0.5\n",
      "131/131 [==============================] - 84s 640ms/step - loss: 7.1330 - acc: 0.5550 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 8/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1237 - acc: 0.5556\n",
      "Epoch 00008: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch7: 0.5\n",
      "131/131 [==============================] - 83s 631ms/step - loss: 7.1178 - acc: 0.5560 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 9/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1263 - acc: 0.5554\n",
      "Epoch 00009: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch8: 0.5\n",
      "131/131 [==============================] - 83s 634ms/step - loss: 7.1203 - acc: 0.5558 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 10/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1211 - acc: 0.5558\n",
      "Epoch 00010: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch9: 0.5\n",
      "131/131 [==============================] - 84s 639ms/step - loss: 7.1254 - acc: 0.5555 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 11/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1211 - acc: 0.5558\n",
      "Epoch 00011: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch10: 0.5\n",
      "131/131 [==============================] - 82s 629ms/step - loss: 7.1254 - acc: 0.5555 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 12/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1237 - acc: 0.5556\n",
      "Epoch 00012: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch11: 0.5\n",
      "131/131 [==============================] - 83s 636ms/step - loss: 7.1203 - acc: 0.5558 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 13/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1263 - acc: 0.5554\n",
      "Epoch 00013: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch12: 0.5\n",
      "131/131 [==============================] - 84s 643ms/step - loss: 7.1203 - acc: 0.5558 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 14/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1108 - acc: 0.5564\n",
      "Epoch 00014: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch13: 0.5\n",
      "131/131 [==============================] - 83s 630ms/step - loss: 7.1203 - acc: 0.5558 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 15/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1186 - acc: 0.5559\n",
      "Epoch 00015: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch14: 0.5\n",
      "131/131 [==============================] - 84s 642ms/step - loss: 7.1229 - acc: 0.5557 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 16/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1340 - acc: 0.5550\n",
      "Epoch 00016: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch15: 0.5\n",
      "131/131 [==============================] - 83s 630ms/step - loss: 7.1229 - acc: 0.5557 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 17/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1263 - acc: 0.5554\n",
      "Epoch 00017: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch16: 0.5\n",
      "131/131 [==============================] - 83s 632ms/step - loss: 7.1279 - acc: 0.5553 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 18/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1186 - acc: 0.5559\n",
      "Epoch 00018: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch17: 0.5\n",
      "131/131 [==============================] - 83s 631ms/step - loss: 7.1203 - acc: 0.5558 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 19/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1288 - acc: 0.5553\n",
      "Epoch 00019: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch18: 0.5\n",
      "131/131 [==============================] - 83s 635ms/step - loss: 7.1178 - acc: 0.5560 - val_loss: 7.1265 - val_acc: 0.5554\n",
      "Epoch 20/20\n",
      "130/131 [============================>.] - ETA: 0s - loss: 7.1340 - acc: 0.5550\n",
      "Epoch 00020: val_acc did not improve from 0.55580\n",
      "\n",
      "Val AUC for epoch19: 0.5\n",
      "131/131 [==============================] - 83s 633ms/step - loss: 7.1254 - acc: 0.5555 - val_loss: 7.1265 - val_acc: 0.5554\n"
     ]
    }
   ],
   "source": [
    "# checkpoint \n",
    "multi_filepath = '/mnt/disks/user/project/Final_Models/first_order_multi_best_modelv2.hdf5'\n",
    "checkpoint = ModelCheckpoint(multi_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "auc_logger = roc_callback()\n",
    "# fit: this will fit the net on 'ablation' samples, only 1 epoch\n",
    "multi_history = multi_first_model.fit_generator(generator = training_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    shuffle=True,\n",
    "                    epochs=20,\n",
    "                    callbacks=[checkpoint,auc_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f06b451e550>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_acc = multi_history.history['acc']\n",
    "multi_val_acc = multi_history.history['val_acc']\n",
    "\n",
    "multi_epochs = range(len(multi_acc))\n",
    "\n",
    "plt.plot(multi_epochs, multi_acc, 'g', label='Training acc')\n",
    "plt.plot(multi_epochs, multi_val_acc, 'b', label='Validation acc')\n",
    "plt.title('Multi Classification Res Model Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi First Order Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_test_generator = DataGenerator(m_test_X, m_test_set,encoder,n_classes=3,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_eval_base_model = load_model(multi_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_predictions = multi_eval_base_model.predict_generator(multi_test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_y_class = np.array(list(multi_test_generator.classes.values()))[:len(multi_predictions)]\n",
    "multi_y = keras.utils.to_categorical(multi_y_class, num_classes=m_nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_prob_max = multi_predictions.max(axis=1).reshape(-1, 1)\n",
    "multi_y_pred = np.where(multi_predictions == multi_prob_max, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_pred = np.argmax(multi_predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Res Model Test Score  0.33426339285714285\n"
     ]
    }
   ],
   "source": [
    "multi_score_test = metrics.accuracy_score(multi_y,multi_y_pred)\n",
    "print('Res Model Test Score ',multi_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 599   0]\n",
      " [  0 599   0]\n",
      " [  0 594   0]]\n"
     ]
    }
   ],
   "source": [
    "multi_cm = confusion_matrix(multi_y_class, multi_pred)\n",
    "print(multi_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       599\n",
      "          1       0.33      1.00      0.50       599\n",
      "          2       0.00      0.00      0.00       594\n",
      "\n",
      "avg / total       0.11      0.33      0.17      1792\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "multi_report = classification_report(multi_y,multi_y_pred)\n",
    "print(multi_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(multi_y, multi_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
